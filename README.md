# ğŸ”§ Modelo Predictivo de Fallas en VehÃ­culos ElÃ©ctricos

Este proyecto implementa un modelo de **machine learning** para predecir fallas en vehÃ­culos elÃ©ctricos (EV) a partir de datos histÃ³ricos de telemetrÃ­a. El objetivo es apoyar estrategias de **mantenimiento predictivo**, reduciendo tiempos de inactividad, costos operativos y riesgos de seguridad asociados a fallos crÃ­ticos. :contentReference[oaicite:0]{index=0}  

---

## ğŸ¯ Objetivo

Construir un **clasificador binario** que estime la probabilidad de que un vehÃ­culo presente una falla (cÃ³digo DTC) en una ventana temporal prÃ³xima, utilizando variables como:

- Estado de carga y salud de la baterÃ­a (SOC, SOH)
- Ciclos de carga
- Temperaturas de baterÃ­a y motor
- RPM y torque del motor
- PresiÃ³n de neumÃ¡ticos y desgaste de frenos
- CÃ³digos de diagnÃ³stico (DTC) :contentReference[oaicite:1]{index=1}  

---

## ğŸ“Š Dataset

- Fuente: archivo `heavy_user.csv` (perfil de uso intensivo).
- Registros: ~43 800 filas con datos horarios (2020â€“2024).
- CaracterÃ­sticas principales:
  - `soc`, `soh`, `charging_cycles`
  - `battery_temp`, `motor_temp`
  - `motor_rpm`, `motor_torque`
  - `tire_pressure`, `brake_pad_wear`
  - `dtc` (variable objetivo, binarizada: 0 = sin fallo, 1 = fallo) :contentReference[oaicite:2]{index=2}  

CaracterÃ­sticas clave del dataset:

- **Sin valores nulos.**
- Columna de voltaje de carga (`charging_voltage`) eliminada por ser constante.
- Columna temporal (`timestamp`) convertida a `datetime` para anÃ¡lisis y luego eliminada para el modelo.
- **Fuerte desbalance de clases**: la mayorÃ­a de registros son â€œsin falloâ€, lo que obliga a usar mÃ©tricas robustas (F1, recall, ROC-AUC).   

---

## ğŸ§ª MetodologÃ­a

### 1. Preprocesamiento de datos

- NormalizaciÃ³n de nombres de columnas a `snake_case`.
- Ajuste de tipos:
  - `timestamp` â†’ `datetime`
  - `dtc` â†’ `category` / entero binario (0/1)
- EliminaciÃ³n de columnas sin variabilidad (p. ej. `charging_voltage`) y de Ã­ndice innecesario.
- AnÃ¡lisis de **outliers**:
  - Se decidiÃ³ **conservar** outliers de variables como `battery_temp`, `motor_rpm`, `motor_torque` y `motor_temp`, ya que representan condiciones crÃ­ticas reales que preceden a las fallas.   

### 2. EDA (AnÃ¡lisis Exploratorio de Datos)

- EstadÃ­sticos descriptivos (`.describe()`).
- Histogramas y KDE para todas las variables numÃ©ricas.
- Boxplots para identificar rangos normales vs. eventos extremos.
- AnÃ¡lisis detallado de la variable objetivo `dtc`:
  - IdentificaciÃ³n de desbalance severo entre clases.
  - DiscusiÃ³n de impacto en mÃ©tricas (accuracy engaÃ±osa vs. F1/recall).   

### 3. Modelado

Se evaluaron distintos algoritmos de clasificaciÃ³n:

- RegresiÃ³n LogÃ­stica
- Random Forest
- XGBoost (modelo principal seleccionado)   

Estrategia:

- DivisiÃ³n en conjuntos de entrenamiento y prueba.
- Manejo del desbalance con:
  - Ajuste de pesos de clase / parÃ¡metros del modelo.
  - Enfoque en mÃ©tricas como **F1-score** y **Recall** para la clase de fallos.
- ComparaciÃ³n de modelos con:
  - Matriz de confusiÃ³n
  - ROC-AUC
  - Precision, Recall, F1-score

### 4. OptimizaciÃ³n

Para el modelo XGBoost:

- BÃºsqueda de hiperparÃ¡metros usando:
  - `GridSearchCV`
  - `RandomizedSearchCV`
- SelecciÃ³n del modelo final en funciÃ³n de F1 y ROC-AUC sobre el conjunto de validaciÃ³n. :contentReference[oaicite:7]{index=7}  

---

## ğŸ§± Estructura sugerida del repositorio

```bash
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ heavy_user.csv        # Dataset original (no se sube si es sensible)
â”‚   â””â”€â”€ processed/            # Pickles / CSV procesados
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_preprocesamiento.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_modelado_basico.ipynb
â”‚   â””â”€â”€ 04_xgboost_optimizacion.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preparation.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ evaluate_model.py
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figuras_y_metricas/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
